# Prototype Alpha v4 â€” System Integration Validation (PWA + Governed AI)

## Purpose of Alpha v4

Prototype Alpha v4 extends the Alpha phase to validate **system-level feasibility**, following the successful completion of Alpha v3, which confirmed the viability of the core learning engine.

The purpose of Alpha v4 is to test whether:
- The PowerMind learning experience remains usable and coherent when delivered as a **Progressive Web App (PWA)**, and
- A **tightly governed, non-conversational AI component** can be integrated without disrupting pedagogy, learner autonomy, or instructional clarity.

Alpha v4 does **not** aim to validate learning outcomes, platform stability, or production readiness.  
It remains firmly within the Alpha scope.

---

## What Alpha v4 Builds On

Alpha v4 builds directly on the outcomes of **Prototype Alpha v3**, which validated:
- Classroom usability of the activity-level learning design
- Instructional clarity for early primary learners
- Learner independence and engagement
- Teacher-perceived pedagogical fit for Grade 1 learners

Alpha v3 formally closed the **learning-engine validation phase**.  
Alpha v4 introduces **system-level risks** for controlled validation.

---

## Scope of Alpha v4

Alpha v4 focuses on **integration behaviour**, not polish, scale, or impact.

### 1. Live Platform Delivery (PWA)

Alpha v4 introduces delivery through a **live web platform**, implemented as a Progressive Web App, to assess:

- Whether navigation and learning flow remain clear when accessed via a browser-installed environment
- Whether delivery constraints interfere with instructional intent
- Whether session handling and navigation feel predictable to users

The PWA implementation is **functional but incomplete** and is treated strictly as an Alpha artefact.

---

### 2. Governed AI Functionality (Non-Conversational)

Alpha v4 introduces a **limited, tightly governed AI component** designed to support learning *without* acting as a chatbot, therapist, coach, or autonomous agent.

AI functionality is intentionally constrained to:
- Predefined pedagogical roles only
- Context-bound explanations and prompts
- Clear behavioural limits and safeguards

Alpha v4 testing evaluates:
- Whether the AI remains within its defined instructional role
- Whether learners correctly understand what the AI is (and is not) for
- Whether AI presence supports clarity rather than distraction
- Whether AI behaviour aligns with **psychology literacy principles**, not SEL or counselling models

AI adaptivity, generative breadth, emotional coaching, and outcome optimisation are **explicitly out of scope**.

---

### 3. Unit-Level Flow Under System Conditions

Alpha v4 tests the **end-to-end system flow** of **Unit 1, Lesson 1** under real platform conditions, including:

- Transitions between screens and activities
- Cognitive load when navigation, AI prompts, and delivery constraints coexist
- System coherence when instructional elements are embedded in a live environment

This testing evaluates **system coherence**, not curriculum completeness.

---

## Visible System Changes in Alpha v4

The live Alpha v4 platform includes a login screen with three visible roles:

- Student  
- Teacher  
- EdSol Admin (internal use only)

The **EdSol Admin** role is an internal administrative and development access point used during platform integration and testing.  
It is not part of learner or teacher workflows and is not within the scope of Alpha v3 learning validation.

---

## What Alpha v4 Does *Not* Test

Alpha v4 does **not** test:
- Learning outcomes or impact
- Behavioural or wellbeing change
- Platform stability at scale
- Performance benchmarks
- Teacher dashboards or analytics
- Classroom synchronisation or multi-user management
- Home learning workflows
- AI effectiveness, adaptivity, or personalisation

These areas are intentionally deferred to later phases.

---

## Testing Approach in Alpha v4

Alpha v4 testing is **exploratory and observational**, focusing on:
- System usability under live delivery conditions
- AI role clarity and non-intrusiveness
- Interaction between learning design and technical constraints
- Identification of friction points that must be resolved before Pre-Beta

Testing outputs are captured through:
- System-level observation
- Iteration notes documenting design decisions
- Controlled synthesis of feedback

No raw learner data is collected or retained.

---

## Status and Known Limitations

Prototype Alpha v4 is **in progress**.

Known limitations include:
- Incomplete PWA functionality
- Early-stage technical roughness
- Limited AI functionality by design
- Ongoing refinement of navigation and interaction smoothness

These limitations are expected and acceptable within Alpha.

---

## Relationship to Pre-Beta

Alpha v4 does **not** represent Pre-Beta.

Progression to Pre-Beta will occur only when:
- Core activities are technically stable and no longer clunky
- Navigation and transitions are predictable and smooth
- AI behaviour is consistent, bounded, and non-distracting
- Unit 1 can be completed end-to-end without workaround or explanation

Until these conditions are met, development remains deliberately within Alpha.

---

## Summary

Prototype Alpha v4 validates whether the PowerMind learning experience can function as a **coherent system** when delivered through a live PWA and supported by a **governed AI component**.

It represents a deliberate extension of the Alpha phase to reduce **system-level risk** before claiming readiness for broader testing, pilot deployment, or learning outcome evaluation.
